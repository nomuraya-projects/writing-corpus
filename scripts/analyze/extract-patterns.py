#!/usr/bin/env python3
"""
æ›¸ãå‘³ãƒ‘ã‚¿ãƒ¼ãƒ³æŠ½å‡º: FC2è¨˜äº‹ã‹ã‚‰è«–ç†å±•é–‹ãƒ»æ„Ÿæƒ…è¡¨ç¾ãƒ»æ§‹é€ ç‰¹å¾´ã‚’æŠ½å‡º

ç›®çš„: AIå­¦ç¿’ç”¨ã®ç‰¹å¾´ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’è‡ªå‹•æŠ½å‡ºã—ã€writing_patternsãƒ†ãƒ¼ãƒ–ãƒ«ã«æ ¼ç´
ä½¿ã„æ–¹: python3 extract-patterns.py [--min-elo SCORE] [--limit N]
å‡ºåŠ›: writing-corpus.db ã® writing_patterns ãƒ†ãƒ¼ãƒ–ãƒ«
"""

import sqlite3
import re
from pathlib import Path
from typing import List, Dict, Tuple
from collections import Counter
import argparse


# ãƒ‘ã‚¿ãƒ¼ãƒ³å®šç¾©
LOGICAL_PATTERNS = {
    "åèªå‹": [
        r"ã€œã˜ã‚ƒãªã„ã‹[ï¼Ÿ?]",
        r"ã€œã¨ã„ã†ã®ã¯ãŠã‹ã—ã„ã‚“ã˜ã‚ƒãªã„ã‹[ï¼Ÿ?]",
        r"ã€œã¨æ€ã‚ãªã„ã‹[ï¼Ÿ?]",
        r"ã€œãªã‚“ã˜ã‚ƒãªã„ã‹[ï¼Ÿ?]",
        r"ã€œã§ã¯ãªã„ã ã‚ã†ã‹[ï¼Ÿ?]"
    ],
    "æ¥µè«–å‰ç½®ãå‹": [
        r"ã¯ã£ãã‚Šè¨€ã£ã¦",
        r"æ­£ç›´ãªè©±",
        r"ç«¯çš„ã«è¨€ãˆã°",
        r"è¦ã™ã‚‹ã«",
        r"çµè«–ã‹ã‚‰è¨€ã†ã¨"
    ],
    "æ®µéšçš„å±•é–‹": [
        r"ã¾ãš[ã€,]",
        r"æ¬¡ã«[ã€,]",
        r"æœ€å¾Œã«[ã€,]",
        r"ç¬¬ä¸€ã«",
        r"ç¬¬äºŒã«",
        r"ãã—ã¦[ã€,]"
    ],
    "å¯¾æ¯”å‹": [
        r"ä¸€æ–¹ã§[ã€,]",
        r"ä»–æ–¹ã§[ã€,]",
        r"ãã‚Œã«å¯¾ã—ã¦",
        r"é€†ã«[ã€,]",
        r"åå¯¾ã«[ã€,]"
    ],
    "å‰ææç¤ºå‹": [
        r"å‰æã¨ã—ã¦[ã€,]",
        r"ãã‚‚ãã‚‚[ã€,]",
        r"ã¾ãšå‰æã¨ã—ã¦",
        r"ã“ã“ã§é‡è¦ãªã®ã¯"
    ]
}

EMOTIONAL_PATTERNS = {
    "è‚¯å®šè¡¨ç¾": [
        r"ã€œã§ã„ã„ã˜ã‚ƒãªã„[!ï¼]",
        r"ç´ æ™´ã‚‰ã—ã„",
        r"æœ€é«˜ã [!ï¼]",
        r"ã“ã‚Œã¯ã„ã„[!ï¼]",
        r"è‰¯ã„ã‚‚ã®",
        r"æ°—ã«å…¥ã£ãŸ"
    ],
    "å¦å®šè¡¨ç¾": [
        r"ã€œã¯ã‚¯ã‚½",
        r"ã¾ãã€ã€œã ãŒ",
        r"æ®‹å¿µãªãŒã‚‰",
        r"ã„ã¾ã„ã¡",
        r"å¾®å¦™",
        r"ãƒ€ãƒ¡"
    ],
    "é©šãè¡¨ç¾": [
        r"ãƒã‚¸ã‹[!ï¼]",
        r"ã¡ã‚‡ã€",
        r"ãŠã„ãŠã„[ã€,]",
        r"ã³ã£ãã‚Š",
        r"é©šã„ãŸ",
        r"ã¾ã•ã‹"
    ],
    "å…±æ„Ÿè¦è«‹": [
        r"ã€œã ã‚ˆã­[ï¼Ÿ?]",
        r"ã€œã˜ã‚ƒã‚“[!ï¼]",
        r"ã€œã§ã—ã‚‡[ï¼Ÿ?]",
        r"ã€œã§ã™ã‚ˆã­[ï¼Ÿ?]"
    ],
    "æ–­å®šå‹": [
        r"ã€œã§ã‚ã‚‹[ã€‚.]",
        r"ã€œã [ã€‚.]",
        r"ã€œã«é•ã„ãªã„",
        r"é–“é•ã„ãªã",
        r"ç¢ºå®Ÿã«"
    ]
}

STRUCTURAL_PATTERNS = {
    "å°å…¥éƒ¨": [
        r"^ã§ã™ã€ãŠã¯ã“ã‚“ã«ã¡ã°ã‚“ã‚[!ï¼]",
        r"^ã•ã¦[ã€,]",
        r"^ã¨ã„ã†ã‚ã‘ã§[ã€,]",
        r"^ä»Šå›ã¯",
        r"^æœ¬æ—¥ã¯"
    ],
    "çµè«–éƒ¨": [
        r"ã¾ã¨ã‚ã‚‹ã¨",
        r"çµè«–ã¨ã—ã¦ã¯",
        r"ã¤ã¾ã‚Š[ã€,]",
        r"ã¨ã„ã†ã“ã¨ã§[ã€,]",
        r"ä»¥ä¸Š[ã€,]"
    ],
    "è£œè¶³éƒ¨": [
        r"ã¡ãªã¿ã«[ã€,]",
        r"ä½™è«‡ã§ã™ãŒ[ã€,]",
        r"è›‡è¶³ãªãŒã‚‰",
        r"ã¤ã„ã§ã«è¨€ã†ã¨",
        r"è£œè¶³ã™ã‚‹ã¨"
    ],
    "å¼•ç”¨ãƒ»å‚ç…§": [
        r"ã€œã«ã‚ˆã‚Œã°[ã€,]",
        r"ã€œã®è¨€è‘‰ã‚’å€Ÿã‚Šã‚Œã°",
        r"å‚è€ƒï¼š",
        r"å¼•ç”¨ï¼š",
        r"å‡ºå…¸ï¼š"
    ],
    "åˆ—æŒ™å‹": [
        r"[â‘ â‘¡â‘¢â‘£â‘¤â‘¥â‘¦â‘§â‘¨â‘©]",
        r"[1-9]\.",
        r"ãƒ»",
        r"- ",
        r"\* "
    ]
}


def extract_patterns_from_article(content: str, pattern_dict: Dict[str, List[str]]) -> Dict[str, List[str]]:
    """
    1ã¤ã®è¨˜äº‹ã‹ã‚‰ç‰¹å®šãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æŠ½å‡º

    Args:
        content: è¨˜äº‹æœ¬æ–‡
        pattern_dict: ãƒ‘ã‚¿ãƒ¼ãƒ³å®šç¾©è¾æ›¸

    Returns:
        ãƒ‘ã‚¿ãƒ¼ãƒ³åˆ¥ã®å‡ºç¾ä¾‹ãƒªã‚¹ãƒˆ
    """
    results = {}

    for pattern_name, pattern_regexes in pattern_dict.items():
        examples = []

        for regex in pattern_regexes:
            matches = re.finditer(regex, content, re.MULTILINE)
            for match in matches:
                # ãƒãƒƒãƒã—ãŸéƒ¨åˆ†ã®å‰å¾Œ20æ–‡å­—ã‚’å«ã‚ã¦æŠ½å‡º
                start = max(0, match.start() - 20)
                end = min(len(content), match.end() + 20)
                context = content[start:end].strip()
                examples.append(context)

        if examples:
            results[pattern_name] = examples[:5]  # å„ãƒ‘ã‚¿ãƒ¼ãƒ³æœ€å¤§5ä¾‹

    return results


def analyze_corpus(db_path: Path, min_elo: int = 1500, limit: int = 100) -> Dict[str, Dict[str, Counter]]:
    """
    ã‚³ãƒ¼ãƒ‘ã‚¹å…¨ä½“ã‹ã‚‰ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æŠ½å‡ºãƒ»é›†è¨ˆ

    Args:
        db_path: ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒ‘ã‚¹
        min_elo: æœ€å°ELOãƒ¬ãƒ¼ãƒ†ã‚£ãƒ³ã‚°
        limit: åˆ†æå¯¾è±¡è¨˜äº‹æ•°ä¸Šé™

    Returns:
        ãƒ‘ã‚¿ãƒ¼ãƒ³ç¨®åˆ¥ã”ã¨ã®é›†è¨ˆçµæœ
    """
    conn = sqlite3.connect(db_path)
    conn.row_factory = sqlite3.Row

    query = """
        SELECT id, title, content
        FROM articles
        WHERE elo_rating >= ? AND content IS NOT NULL AND content != ''
        ORDER BY elo_rating DESC
        LIMIT ?
    """

    cursor = conn.execute(query, (min_elo, limit))
    articles = cursor.fetchall()

    print(f"åˆ†æå¯¾è±¡: {len(articles)}ä»¶ã®è¨˜äº‹ï¼ˆELO >= {min_elo}ï¼‰")

    # ãƒ‘ã‚¿ãƒ¼ãƒ³åˆ¥ã®é›†è¨ˆ
    logical_counter = Counter()
    emotional_counter = Counter()
    structural_counter = Counter()

    # ä¾‹æ–‡ã®åé›†
    logical_examples = {}
    emotional_examples = {}
    structural_examples = {}

    for i, article in enumerate(articles, 1):
        content = article['content']

        # è«–ç†å±•é–‹ãƒ‘ã‚¿ãƒ¼ãƒ³
        logical_matches = extract_patterns_from_article(content, LOGICAL_PATTERNS)
        for pattern_name, examples in logical_matches.items():
            logical_counter[pattern_name] += len(examples)
            if pattern_name not in logical_examples:
                logical_examples[pattern_name] = []
            logical_examples[pattern_name].extend(examples)

        # æ„Ÿæƒ…è¡¨ç¾ãƒ‘ã‚¿ãƒ¼ãƒ³
        emotional_matches = extract_patterns_from_article(content, EMOTIONAL_PATTERNS)
        for pattern_name, examples in emotional_matches.items():
            emotional_counter[pattern_name] += len(examples)
            if pattern_name not in emotional_examples:
                emotional_examples[pattern_name] = []
            emotional_examples[pattern_name].extend(examples)

        # æ§‹é€ ç‰¹å¾´ãƒ‘ã‚¿ãƒ¼ãƒ³
        structural_matches = extract_patterns_from_article(content, STRUCTURAL_PATTERNS)
        for pattern_name, examples in structural_matches.items():
            structural_counter[pattern_name] += len(examples)
            if pattern_name not in structural_examples:
                structural_examples[pattern_name] = []
            structural_examples[pattern_name].extend(examples)

        if i % 20 == 0:
            print(f"  å‡¦ç†ä¸­... {i}/{len(articles)}")

    conn.close()

    return {
        "è«–ç†å±•é–‹": {"counter": logical_counter, "examples": logical_examples},
        "æ„Ÿæƒ…è¡¨ç¾": {"counter": emotional_counter, "examples": emotional_examples},
        "æ§‹é€ ç‰¹å¾´": {"counter": structural_counter, "examples": structural_examples}
    }


def save_patterns_to_db(db_path: Path, analysis_results: Dict[str, Dict[str, Counter]]):
    """
    æŠ½å‡ºã—ãŸãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«ä¿å­˜

    Args:
        db_path: ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒ‘ã‚¹
        analysis_results: åˆ†æçµæœ
    """
    conn = sqlite3.connect(db_path)

    # æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ã‚’ã‚¯ãƒªã‚¢
    conn.execute("DELETE FROM writing_patterns")

    for pattern_type, data in analysis_results.items():
        counter = data['counter']
        examples = data['examples']

        for pattern_name, count in counter.items():
            # ä¾‹æ–‡ã‚’JSONå½¢å¼ã§ä¿å­˜ï¼ˆæœ€å¤§10ä¾‹ï¼‰
            example_list = list(set(examples.get(pattern_name, [])))[:10]
            examples_json = '\n---\n'.join(example_list)

            # ãƒ‘ã‚¿ãƒ¼ãƒ³ã®æ­£è¦è¡¨ç¾ã‚’å–å¾—
            if pattern_type == "è«–ç†å±•é–‹":
                pattern_regex = '|'.join(LOGICAL_PATTERNS.get(pattern_name, []))
            elif pattern_type == "æ„Ÿæƒ…è¡¨ç¾":
                pattern_regex = '|'.join(EMOTIONAL_PATTERNS.get(pattern_name, []))
            else:
                pattern_regex = '|'.join(STRUCTURAL_PATTERNS.get(pattern_name, []))

            conn.execute("""
                INSERT INTO writing_patterns (pattern_type, pattern_name, pattern, examples)
                VALUES (?, ?, ?, ?)
            """, (pattern_type, pattern_name, pattern_regex, examples_json))

            print(f"  ä¿å­˜: {pattern_type} > {pattern_name} ({count}å›å‡ºç¾)")

    conn.commit()
    conn.close()

    print(f"\nâœ… ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«ä¿å­˜ã—ã¾ã—ãŸ")


def print_summary(analysis_results: Dict[str, Dict[str, Counter]]):
    """åˆ†æçµæœã®ã‚µãƒãƒªãƒ¼ã‚’è¡¨ç¤º"""

    print("\nğŸ“Š æŠ½å‡ºãƒ‘ã‚¿ãƒ¼ãƒ³ã‚µãƒãƒªãƒ¼\n")

    for pattern_type, data in analysis_results.items():
        counter = data['counter']

        print(f"## {pattern_type}")

        if counter:
            for pattern_name, count in counter.most_common(10):
                print(f"  - {pattern_name}: {count}å›")
        else:
            print("  ï¼ˆè©²å½“ãƒ‘ã‚¿ãƒ¼ãƒ³ãªã—ï¼‰")

        print()


def main():
    parser = argparse.ArgumentParser(description="æ›¸ãå‘³ãƒ‘ã‚¿ãƒ¼ãƒ³æŠ½å‡º")

    parser.add_argument("--min-elo", type=int, default=1500, help="æœ€å°ELOãƒ¬ãƒ¼ãƒ†ã‚£ãƒ³ã‚°ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 1500ï¼‰")
    parser.add_argument("--limit", type=int, default=100, help="åˆ†æå¯¾è±¡è¨˜äº‹æ•°ä¸Šé™ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 100ï¼‰")
    parser.add_argument("--summary-only", action="store_true", help="ã‚µãƒãƒªãƒ¼ã®ã¿è¡¨ç¤ºï¼ˆDBã«ä¿å­˜ã—ãªã„ï¼‰")

    args = parser.parse_args()

    # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒ‘ã‚¹
    project_root = Path(__file__).parent.parent.parent
    db_path = project_root / "data" / "corpus" / "writing-corpus.db"

    if not db_path.exists():
        print(f"âŒ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {db_path}")
        print("   å…ˆã« migrate-to-sqlite.py ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„")
        return

    print("æ›¸ãå‘³ãƒ‘ã‚¿ãƒ¼ãƒ³æŠ½å‡ºã‚’é–‹å§‹ã—ã¾ã™...\n")

    # ã‚³ãƒ¼ãƒ‘ã‚¹åˆ†æ
    analysis_results = analyze_corpus(db_path, min_elo=args.min_elo, limit=args.limit)

    # ã‚µãƒãƒªãƒ¼è¡¨ç¤º
    print_summary(analysis_results)

    # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«ä¿å­˜
    if not args.summary_only:
        save_patterns_to_db(db_path, analysis_results)
    else:
        print("ï¼ˆ--summary-only ãŒæŒ‡å®šã•ã‚ŒãŸãŸã‚ã€ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«ã¯ä¿å­˜ã—ã¾ã›ã‚“ï¼‰")


if __name__ == "__main__":
    main()
